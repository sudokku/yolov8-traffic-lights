{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"dima806/traffic_sign_detection\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"dima806/traffic_sign_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Bicycles crossing', 1: 'Children crossing', 2: 'Danger Ahead', 3: 'Dangerous curve to the left', 4: 'Dangerous curve to the right', 5: 'Dont Go Left', 6: 'Dont Go Left or Right', 7: 'Dont Go Right', 8: 'Dont Go straight', 9: 'Dont Go straight or left', 10: 'Dont overtake from Left', 11: 'Fences', 12: 'Go Left', 13: 'Go Left or right', 14: 'Go Right', 15: 'Go left or straight', 16: 'Go right or straight', 17: 'Go straight', 18: 'Go straight or right', 19: 'Heavy Vehicle Accidents', 20: 'Horn', 21: 'No Car', 22: 'No Uturn', 23: 'No entry', 24: 'No horn', 25: 'No stopping', 26: 'Road Divider', 27: 'Roundabout mandatory', 28: 'Speed limit (15km/h)', 29: 'Speed limit (30km/h)', 30: 'Speed limit (40km/h)', 31: 'Speed limit (50km/h)', 32: 'Speed limit (5km/h)', 33: 'Speed limit (60km/h)', 34: 'Speed limit (70km/h)', 35: 'Train Crossing', 36: 'Under Construction', 37: 'Unknown', 38: 'Uturn', 39: 'Zebra Crossing', 40: 'ZigZag Curve', 41: 'keep Left', 42: 'keep Right', 43: 'speed limit (80km/h)', 44: 'watch out for cars'}\n"
     ]
    }
   ],
   "source": [
    "print(model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'height': 224, 'width': 224}\n"
     ]
    }
   ],
   "source": [
    "print(processor.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 224)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 224)\n",
    "\n",
    "id2label = model.config.id2label\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: failed to capture image\")\n",
    "        break\n",
    "\n",
    "    # Preprocess the image\n",
    "    inputs = processor(images=frame, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Get the predicted class label\n",
    "    predicted_class_idx = outputs.logits.argmax(-1).item()\n",
    "    label = id2label[predicted_class_idx]\n",
    "    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
